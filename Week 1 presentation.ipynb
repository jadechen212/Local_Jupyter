{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6aea8f",
   "metadata": {},
   "source": [
    "# Week 1 presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4470bb92",
   "metadata": {},
   "source": [
    "The first week is pretty much about setting everything up... \n",
    "\n",
    "## login for euler cluster and try to set up login without using password "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1069da",
   "metadata": {},
   "source": [
    "the first thing is to login ssh jiaychen@euler.ethz.ch account and conduct basic commands in bash "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910bb63",
   "metadata": {},
   "source": [
    "### Some basic bash commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cb38ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd # change current directory;\n",
    "cd .. # to the parent directory of current directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd # print current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir #create a new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bb0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls # print a list of file or working \n",
    "ls -lyrth\n",
    "ls -lyath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm # remove\n",
    "rm * #remove every file in the current directory\n",
    "rm -r # remove a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp # copy a file \n",
    "cp [file name] [directory to be moved to]\n",
    "cp -r #copy a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86764c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "touch # create a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cc454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi #using vim to edit file\n",
    "i #insert\n",
    "ZZ #exit\n",
    "[control]V #paste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9dda5",
   "metadata": {},
   "source": [
    "### Set up euler using ssh keys without password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84eea3af",
   "metadata": {},
   "source": [
    "first thing would be creating ssh key using following commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh-keygen -t ed25519 -f $HOME/.ssh/id_ed25519_euler  \n",
    "ssh-copy-id -i $HOME/.ssh/id_ed25519_euler.pub    jiaychen@euler.ethz.ch\n",
    "ssh-add --apple-use-keychain ~/.ssh/id_ed25519_euler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3524c",
   "metadata": {},
   "source": [
    "then create a config file in the directory of .ssh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f43371",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa5fcae",
   "metadata": {},
   "source": [
    "then edit the config with following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Host euler.ethz.ch\n",
    "    HostName euler.ethz.ch\n",
    "    User avillas\n",
    "\n",
    "Host * \n",
    "   UseKeychain yes \n",
    "   AddKeysToAgent yes \n",
    "   IdentityFile ~/.ssh/id_ed25519_euler\n",
    "\n",
    "##Then run this outside of the config\n",
    "ssh-add -K ~/.ssh/id_ed25519_euler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b020a4",
   "metadata": {},
   "source": [
    "with everything settled correctly, then euler cluster is avaliable to login without password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc33397",
   "metadata": {},
   "source": [
    "## Basic understanding of FASTQ, BAM and VCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0033012",
   "metadata": {},
   "source": [
    "### FASTQ\n",
    "FASTQ file is a file that split the whole genome sequence into 150 bp fragments\n",
    "- 1st line is the name of the read: what sequence machine created, where the gene located in the cell\n",
    "- 2nd line is the 150 bp of the DNA\n",
    "- 3rd line of the + for aesthetics\n",
    "- 4th line: quality score of the read (how confident the base call is correct)\n",
    "\n",
    "one limitation of FASTQ is that we don't know the exact location of the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa999c0f",
   "metadata": {},
   "source": [
    "### BAM\n",
    "When sequences are aligned using FASTQ file and compare to a reference genome, the whole genome sequence is stored in the BAM file (binary) and therefore may need to change to SAM file to be readable.\n",
    "\n",
    "example SAM file\n",
    "![SAM](notes/SAM.png)\n",
    "For each of the column:\n",
    "1. Query name: identify any individual reads\n",
    "2. FLAG value: flag score \n",
    "3. Reference name: SQ line\n",
    "4. Position: \n",
    "5. Mapping quality: confident score \n",
    "6. CIGAR: continuity or discontinuity in alignment (Match, deletion, insertion)\n",
    "7. Reference name for mate; “=” if identical to the reference name value\n",
    "8. Position of mate (analogous to 4)\n",
    "9. Template length: length of template sequence \n",
    "10. Sequence\n",
    "11.\tQuality string\n",
    "12.\tPredefined tags: additional info for the alignment/ read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d7daee",
   "metadata": {},
   "source": [
    "### VCF\n",
    "\n",
    "VCF file contains all the difference in base pairs for the individual comparing to the reference genome\n",
    "for the different column:\n",
    "![VCF](notes/VCF.png)\n",
    "\n",
    "- #CHROM: number of chromosomes\n",
    "- POS: position on the chromosome\n",
    "- ID: names (rs ids)\n",
    "- REF:reference base\n",
    "- ALT: variant base\n",
    "- QUAL: A quality score \n",
    "- FILTER: see the variation failed or PASS a given set of filters\n",
    "- INFO: key-values describing the variation \n",
    "- FORMAT: list of fields describing the data\n",
    "- SAMPLEs: values given for the FORMAT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2762de",
   "metadata": {},
   "source": [
    "\n",
    "## Other settings in cluster\n",
    "\n",
    "\n",
    "### Set Conda in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f0b275",
   "metadata": {},
   "source": [
    "download miniconda locally and then using filezilla to move the file to euler.ethz.ch using the same username and password to login euler\n",
    "\n",
    "To activate conda on the cluster, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ab75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate\n",
    "conda deactivate # the (base) in front of username would be disappear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc742358",
   "metadata": {},
   "source": [
    "bcftools is used in VCF and BCF, to install the package of bcftools, we need to run the commands in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136fe640",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda bcftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0ec44",
   "metadata": {},
   "source": [
    "### Generating jupyter notebooks and synchronizing to Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2246a4c5",
   "metadata": {},
   "source": [
    "create a ETH_jupyter folder in github then install jupyter in the environment using following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b20edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip3 install jupyter\n",
    "pip3 install --upgrade jupyter ##If already installed for updating it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe422436",
   "metadata": {},
   "source": [
    "#### synchronizing (this part is not ready yet but will keep working on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d5b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "git config --global user.email jadechen212@gmail.com\n",
    "git config --global user.name jadechen212\n",
    "##These steps are generally not needed as it was already defined and stays like this\n",
    "cd /cluster/home/avillas/\n",
    "mkdir Jupyter_au\n",
    "cd /cluster/home/avillas/Jupyter_au\n",
    "git init #this step is necessary if starting the repository from a remote folder\n",
    "git remote add origin https://github.com/Audald/Jupyter_au #This is the default http source and how I work locally. However, I had to change it to the below one for Leonhard as I wanted the SSH key not to be asked for user and password all the time.\n",
    "git remote set-url origin git@github.com:Audald/Jupyter_au.git #This needs to be used only when origin has been assigned to a different endpoint and you want to modify it\n",
    "git remote -v #To see what are the origins\n",
    "git add --all #adding new changes\n",
    "git commit -am 'New repository in Github, from the Leonhard cluster' #Documenting new changes\n",
    "git push origin master #propagating new changes. user and password will not be requested if remote origin and SSH keys have been properly provided\n",
    "----\n",
    "git push ##is possible if the following line has been applied\n",
    "git push --set-upstream origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad9058b",
   "metadata": {},
   "source": [
    "if still not working, then the alternative would be using jupyter locally and upload to GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a02899",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Self study on Snakemake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b08ffa",
   "metadata": {},
   "source": [
    "A workflow is defined in a 'snakefiles'\n",
    "\n",
    "A rule definition specifies (i)a name; (ii) any number of input and output files and (iii) either a shell command or Prython code that creares the output from input.\n",
    "\n",
    "Generally the workflow for snakemake would be .fastq--> .sai(intermediate) -->.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdfee8",
   "metadata": {},
   "source": [
    "The rule fastq_to_sai --> map the given .fastq file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41df76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule fastq_to_sai:\n",
    "    input: ref = REF, reads =\"{sample}.{group}.fastq\"\n",
    "    output: temp(\"{sample}.{group}.sai\")\n",
    "    shell: \"bwa aln {input.ref} {input.reads}> {output}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7158e4",
   "metadata": {},
   "source": [
    "BWA is used to read mapping, that produce suuffix array interval (.sai) and need to be converted to common format .bam\n",
    "\n",
    "This is conducted by rule sai_to_bam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aadb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule sai_to_bam:\n",
    "    input: REF, \"{sample}.1.sai\", \"{sample}.2.sai\", \n",
    "    \"{sample}.1.fastq\", \"{sample}.2.fastq\" \n",
    "    output: protected(\"{sample}.bam\")\n",
    "    shell: \"bwa sampe {input} j samtools view -Sbh -4{output}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323e32ad",
   "metadata": {},
   "source": [
    "Install snakemake in cluster using the following command (important: condo cannot install snakemake directly and we need to use mamba as a suppliment to install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1aaa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ conda install -n base -c conda-forge mamba\n",
    "$ conda activate base # by default it should already be activated\n",
    "$ mamba create -c conda-forge -c bioconda -n snakemake snakemake\n",
    "$ conda activate snakemake\n",
    "$ snakemake --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4076d4f8",
   "metadata": {},
   "source": [
    "change the repository of snakemake to a ideal one called snakemake_lsf in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a92a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/.config/\n",
    "mkdir snakemake\n",
    "cd snakemake/\n",
    "git clone https://github.com/AnimalGenomicsETH/snakemake_lsf.git # for some reason, only https works for me not the git@github.com\n",
    "cd snakemake_lsf/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c247e",
   "metadata": {},
   "source": [
    "## Working with bcftools in the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfdf573",
   "metadata": {},
   "source": [
    "To learn a bit more about bcftools, several steps in conducted in the cluster of some .vcf.gz files\n",
    "We first working in the headmode (may not be allowed in some cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cf8a40",
   "metadata": {},
   "source": [
    "1. First step is to create the index file for all vcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12217026",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools index [file name.vcf.gz] ## This create vcf.gz.csi by default; tbi can be created if use -tbi/-t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d7aeab",
   "metadata": {},
   "source": [
    "2. Then we retrieve the stats file for each of the vcf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb1210",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools stats [file name.vcf.gz] > [file name.stats] \n",
    "                                ## This gives the statistic results and store the file as .stats in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889c9683",
   "metadata": {},
   "source": [
    "3. Combine multiple vcf files into one file (usually compressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d841bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools concat -Oz -o [the new file name.vcf.gz] [file name1.vcf.gz] [file name2.vcf.gz] \n",
    "                                 ## Concat combine multiple files togther as one compressed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e7e41",
   "metadata": {},
   "source": [
    "4. Selection of columns in the combined vcf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view -s RMXXXX [the combined file.vcf.gz] -Oz -o RMXXXX.vcf.gz\n",
    "## This select the specific RMXXXX sample from the concat file and store as compressed file\n",
    "\n",
    "###Important: remember to create the index for the combined file first otherwise it won't work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e9a4b",
   "metadata": {},
   "source": [
    "5. Selection of chromosomes in the file for one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dd99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view -r 5 [BSWXXXXXX.vcf.gz] -Oz -o chromosome_5.vcf.gz\n",
    "\n",
    "## This select specific colomn of the chromosome number on the file and saved as compressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aef872",
   "metadata": {},
   "source": [
    "6. Selection of columns with specific quality in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcftools view -i 'REF=\"C\"'[chromosome_5.vcf.gz] -Oz -o REF_C.vcf.gz\n",
    "\n",
    "## This select the columns with reference sequence to be C in the chromosome_5 file.\n",
    "\n",
    "###This could also be conducted through awk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f698e7",
   "metadata": {},
   "source": [
    "After all these steps, we used index for the newly created files and move on to the comp. mode, the first thing is to submit the job.\n",
    "\n",
    "we first created a new directory with exact same *vcf.gz files and all comp.mode jobs are completed in that directory. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3dd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsub \"bcftools index filename.vcf.gz\"\n",
    "## this submit jobs to another device and run it there\n",
    "\n",
    "bjobs ## Check if there is still unfinished jobs and show the status of unfinished jobs\n",
    "\n",
    "bpeek #display the output of the job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8319841",
   "metadata": {},
   "source": [
    "Each of the job generating a report as lsf.o22545* file when the job is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "less(lsf.022545XXXXX) ## To see specific report\n",
    "grep 'Successfully completed.' lsf.022545* # Show all successfully completed works\n",
    "rm lsf.022545* #After checking it, the report can be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58564b8f",
   "metadata": {},
   "source": [
    "Similar commends as the headmode is used to send jobs from step 1-6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad56661",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Snakemake is introduced in this case as it could run jobs individually once the output is ready and therefore it could also be used in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddad15e",
   "metadata": {},
   "source": [
    "Firstly we need to settle up snakemake in the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda activate snakemake ## same as the installation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c72baa",
   "metadata": {},
   "source": [
    "Then we need to create a directory inside the VCF folder for snakemake (snakie)\n",
    "After set up the directory in snakie, we can see several files created: snake_submit and Snakefile\n",
    "\n",
    "However, one problem is that once a different environment is created, the bcftools is not installed and therefore we need to run the installation again for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066618a4",
   "metadata": {},
   "source": [
    "One advantage is to allow different version of package used in seperate environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe76c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda bcftools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146204b9",
   "metadata": {},
   "source": [
    "Inside the Snakefile, three rules already created to conduct the first 3 steps similar to using bcftools in the headmode as well as comp.mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f29a94",
   "metadata": {},
   "source": [
    "Generally, the structure of the Snakefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc2e5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcfs_origin\n",
    "\n",
    "vcfs_end\n",
    "\n",
    "rule all ## the general rule that applies to all rules created\n",
    "##all the final output we need with all rules\n",
    "\n",
    "rule [rule name]\n",
    "    input: \n",
    "        vcf = # the file used\n",
    "    output:\n",
    "        vcf = # the output file name,\n",
    "        csi = # the output file index form\n",
    "        stats = # the output file with stats form\n",
    "    threads: N ## number of thread used to run the rule\n",
    "    resources:\n",
    "        mem_mb = 500,  ## the memory required\n",
    "        walltime = '00:20' # the wall clock time \n",
    "    shell: ## the command to be run to retrieve data\n",
    "        ## usually bcftools commands but sometimes needs to change the vcfs_origin or vcfs_end to run properly\n",
    "        '''\n",
    "        bcftools index {input.vcf} ## this vcf is connected to the naming in input \\n \\\n",
    "        bcftools stats {input.vcf} > {output.stats}\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214495ba",
   "metadata": {},
   "source": [
    "If the output of a rule before is used as the input of the next rule, we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c746f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input:\n",
    "    vcf = rules.[rule name].output.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d6763",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becdd44b",
   "metadata": {},
   "source": [
    "Here are some commands to use after we finish edit the Snakefile (sometimes vim is not a good choice to edit as it won't automatically set everything, alternatives such as sublime text is used locally to edit the rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa989848",
   "metadata": {},
   "outputs": [],
   "source": [
    "snakemake -n # can be used as a dry-run and see if the workflow is defined properly.\n",
    "snakemake -cores N/-cN ## the number of CPU cores to be used at the same time.\n",
    "snakemake -R [specific rule] ## this allow you to run specific rules in snakemake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019b906",
   "metadata": {},
   "source": [
    "In order to run successfully, we need to edit rule all by first creating the workflow chart (DAG) and put all the last-step output in the rule all part.\n",
    "\n",
    "\n",
    "In our case the flow for all six steps can be distinguished and the output we need would be the stats file for \"REF_C.stats\" and \"RM1900.stats\"; since \"BSWXXXXXX.vcf.gz\" is used for rules followed, we also need to put \"BSWXX.stats\" in the rule all to get the data we want.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56a2ae",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Another useful tool to introduce would be the Linux Screen as a similar function of running jobs distantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen ## this create a new screen with default name and we can run all snakemake command in it when we are away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6dc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen -S [file name] ## this create a new named session with the name you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5946a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ctrl] a+d ## detach the screen session and it will continue running when you are away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c33497",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen -r ## resume the session; if multiple sessions are ongoing, the ID needs to be specified after r "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07debdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen ls ## list all the current sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de985065",
   "metadata": {},
   "source": [
    "\n",
    "After we detach the session, the snakemake commands is continuing running and we could eventually get all the results in our VCF folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba37834",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1201e548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b66142c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a33d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
